%tensorflow_version 2.x
from tensorflow.keras.datasets import cifar10
from tensorflow.keras.models import Model
from tensorflow.keras.utils import plot_model # This will print model architecture.
from tensorflow.keras.layers import Input, Concatenate, Dense, Dropout, Flatten, Activation # We add the Concatentate function
from tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D, SeparableConv2D # We will use AveragePooling2D. Similar to MaxPooling but now we take the average value in the window.
from tensorflow.keras.layers import BatchNormalization
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras import backend
from sklearn.model_selection import train_test_split
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd


# fix random seed for reproducibility
np.random.seed(42)

# load data
(train_images, train_labels),(test_images, test_labels) = cifar10.load_data()

# Reshape xblock data and normalize
train_images =  train_images.reshape((50000, 32, 32, 3))
train_images = train_images.astype('float32')/train_images.max()

test_images =  test_images.reshape((10000, 32, 32, 3))
test_images = test_images.astype('float32')/test_images.max()

# convert to labels to categorical
train_labels = to_categorical(train_labels)
test_labels = to_categorical(test_labels)

#split into validation
x_train, x_val, y_train, y_val = train_test_split(train_images, train_labels, test_size=0.25, random_state=42)

backend.clear_session()

# Input model
visible = Input(shape=(32,32,3))

# Create Tower 1
conv11 = Conv2D(32, (3,3), padding = 'same', activation='relu')(visible)
pool11 = MaxPooling2D((2, 2), padding = 'same')(conv11)

# Create Tower 2
conv21 = Conv2D(32, (3,3), padding = 'same', activation='relu')(visible)
pool21 = MaxPooling2D((2,2), padding = 'same')(conv21)

# Concatentate
merge = Concatenate(axis=-1)([pool11, pool21])

# Flatten into fully connected layer
flat = Flatten()(merge)

# Hidden connected layer and output
hidden = Dense(32, activation='relu')(flat)
drop = Dropout(0.5)(hidden)
output = Dense(10, activation='softmax')(drop)

model_example = Model(inputs=visible, outputs=output)
# plot graph
plot_model(model_example)

# Build and print (plot) the model architecture found in figure 7.8 (Chollet)
backend.clear_session()

vislayer = Input(shape=(32,32,3))

#conv1
conv11 = Conv2D(128, 1,strides=2, padding='same', activation='relu')(vislayer)

#Conv2
conv21 = Conv2D(128, 1, padding='same', activation='relu')(vislayer)
conv22 = Conv2D(128, 3, padding='same', activation='relu', strides=2)(conv21)

#AvgPool
avpool31 = AveragePooling2D(3, strides=2, padding='same')(vislayer)
avpool32 = Conv2D(128, 3,activation='relu', padding='same')(avpool31)

#Conv3
conv41 = Conv2D(128, 1, padding='same', activation='relu')(vislayer)
conv42 = Conv2D(128, 3, padding='same', activation='relu')(conv41)
conv43 = Conv2D(128, 3, padding='same', activation='relu', strides=2)(conv42)

#concat
merged = Concatenate(axis=-1)([conv11, conv22, avpool32, conv43])

flat = Flatten()(merged)
hidden = Dense(128, activation='relu')(flat)
output = Dense(10, activation='softmax')(hidden)

#Model - to duplicate exactly what is in the book I can use the merged layer as the output to plot the model
incepmodel = Model(inputs=vislayer, outputs=merged)

#plot
plot_model(incepmodel)

# Build the model and print (plot) the model.
backend.clear_session()

#Visible layer
vislayer = Input(shape=(32,32,3))

#First nets and Normalization
conv01 = Conv2D(128, 3,strides=2, padding='same', activation='relu')(vislayer)
conv02 = Conv2D(128, 3,strides=2, padding='same', activation='relu')(conv01)

visnorm = BatchNormalization()(conv02)

#conv1
conv11 = Conv2D(128, 1,strides=2, padding='same', activation='relu')(visnorm)

#Conv2
conv21 = Conv2D(128, 1, padding='same', activation='relu')(visnorm)
conv22 = Conv2D(128, 3, padding='same', activation='relu', strides=2)(conv21)

#AvgPool
avpool31 = AveragePooling2D(3, strides=2, padding='same')(visnorm)
avpool32 = Conv2D(128, 3,activation='relu', padding='same')(avpool31)

#Conv3
conv41 = Conv2D(128, 1, padding='same', activation='relu')(visnorm)
conv42 = Conv2D(128, 3, padding='same', activation='relu')(conv41)
conv43 = Conv2D(128, 3, padding='same', activation='relu', strides=2)(conv42)

#concat
merged = Concatenate(axis=-1)([conv11, conv22, avpool32, conv43])

bnorm = BatchNormalization()(merged)
conv5 = Conv2D(128, 3, padding='same', activation='relu')(bnorm)
conv6 = Conv2D(128, 3, padding='same', activation='relu')(conv5)
bnorm2 = BatchNormalization()(conv6)
flat = Flatten()(bnorm2)
hidden = Dense(128, activation='relu')(flat)
drop = Dropout(0.5)(hidden)
output = Dense(10, activation='softmax')(drop)

#Model
incepmodel = Model(inputs=vislayer, outputs=output)

#plot
plot_model(incepmodel)
